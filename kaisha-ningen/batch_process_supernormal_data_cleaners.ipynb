{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Kaisha Ningen - Company Man\n",
        "## This is a project to create a Contextual Retrieval Agent 会社人間 that can answer questions about the company based on meeting notes captured by Supernormal and Otter.AI.\n",
        "\n",
        "This notebook performs batch processing on the Markdown files to include data cleaning. The intent is to prepare these files for vectorization into a database like [*Qdrant*](https://qdrant.tech/).\n",
        "\n"
      ],
      "metadata": {
        "id": "4-pEvGL-3T0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFgSyW74qi7v"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Install necessary libraries if not already installed\n",
        "try:\n",
        "    import markdown\n",
        "except ImportError:\n",
        "    !pip install markdown\n",
        "    import markdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main directory and the sub-directory to exclude\n",
        "directory_path = '/content/drive/MyDrive/Supernormal-Transcripts' # Define the path of the input directory\n",
        "exclude_subdirectory = '/content/drive/MyDrive/Supernormal-Transcripts/processed-files' # Define excluded directories if necessary\n",
        "output_directory = '/content/drive/MyDrive/Supernormal-Transcripts/processed-files'  # Define output directory"
      ],
      "metadata": {
        "id": "UsJewym50bHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all .md files in the directory, excluding those in the processed-files sub-directory\n",
        "file_paths = [\n",
        "    os.path.join(root, file)\n",
        "    for root, dirs, files in os.walk(directory_path)\n",
        "    if exclude_subdirectory not in root  # Exclude files from the 'processed-files' directory - if you use Google Drive, edit as needed\n",
        "    for file in files\n",
        "    if file.endswith('.md')\n",
        "]"
      ],
      "metadata": {
        "id": "_6cWyNBptGer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    cleaned_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "    return cleaned_text\n",
        "\n",
        "def standardize_dates(text):\n",
        "    date_pattern = r'\\b(\\d{4}-\\d{2}-\\d{2})\\b'\n",
        "    time_pattern = r'\\b(\\d{2}:\\d{2})\\b'\n",
        "\n",
        "    standardized_text = re.sub(date_pattern, lambda x: datetime.strptime(x.group(), '%Y-%m-%d').strftime('%Y-%m-%d'), text)\n",
        "    standardized_text = re.sub(time_pattern, lambda x: datetime.strptime(x.group(), '%H:%M').strftime('%H:%M'), standardized_text)\n",
        "\n",
        "    return standardized_text\n"
      ],
      "metadata": {
        "id": "KIkqBJvDuagn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_files = []\n",
        "# Loop through the files and process them\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r') as file:\n",
        "        # Read the content from the file\n",
        "        content = file.read()\n",
        "\n",
        "        # Step 1: Clean text\n",
        "        content = clean_text(content)\n",
        "        # Step 2: Standardize dates and times\n",
        "        content = standardize_dates(content)\n",
        "        processed_files.append((content, file_path)) # store processed files in a list of (content, filepath) pairs.\n"
      ],
      "metadata": {
        "id": "Oq4naPQsueRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert filename to kebab-case\n",
        "def convert_to_kebab_case(filename):\n",
        "    kebab_name = filename.lower().replace(' ', '-').replace('_', '-').replace('.md', '.txt')\n",
        "    return kebab_name\n",
        "\n",
        "# Save each processed file with kebab-case filenames in the 'processed-files' subfolder\n",
        "for content, path in processed_files:\n",
        "    original_filename = os.path.basename(path)\n",
        "    new_filename = convert_to_kebab_case(original_filename)\n",
        "    output_path = os.path.join(output_directory, new_filename)  # Use output_directory\n",
        "\n",
        "    # Write the processed content to a new .txt file\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f'Saved cleaned file as {output_path}')\n"
      ],
      "metadata": {
        "id": "ZhFAEmuquhcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}